digraph {
	graph [size="36.0,36.0"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	140039748610304 [label="
 (1, 1, 224, 224)" fillcolor=darkolivegreen1]
	140039748624448 [label=LeakyReluBackward0]
	140039748624736 -> 140039748624448
	140039748624736 [label=SigmoidBackward0]
	140039748624592 -> 140039748624736
	140039748624592 [label=NativeLayerNormBackward0]
	140039748624496 -> 140039748624592
	140039748624496 [label=AddBackward0]
	140039748624880 -> 140039748624496
	140039748624880 [label=Log1PBackward0]
	140039748625024 -> 140039748624880
	140039748625024 [label=MulBackward0]
	140039748625120 -> 140039748625024
	140039748625120 [label=ConvolutionBackward0]
	140039748625264 -> 140039748625120
	140039748625264 [label=LeakyReluBackward1]
	140039748625456 -> 140039748625264
	140039748625456 [label=ConvolutionBackward0]
	140039748625552 -> 140039748625456
	140039748625552 [label=LeakyReluBackward1]
	140039748625744 -> 140039748625552
	140039748625744 [label=ConvolutionBackward0]
	140039748625840 -> 140039748625744
	140039748625840 [label=CatBackward0]
	140039748626032 -> 140039748625840
	140039748626032 [label=ConvolutionBackward0]
	140039748626176 -> 140039748626032
	140039748626176 [label=LeakyReluBackward1]
	140039748626368 -> 140039748626176
	140039748626368 [label=ConvolutionBackward0]
	140039748626464 -> 140039748626368
	140039748626464 [label=LeakyReluBackward1]
	140039748626656 -> 140039748626464
	140039748626656 [label=ConvolutionBackward0]
	140039748626752 -> 140039748626656
	140039748626752 [label=MaxPool2DWithIndicesBackward0]
	140039748625984 -> 140039748626752
	140039748625984 [label=MulBackward0]
	140039748626992 -> 140039748625984
	140039748626992 [label=LeakyReluBackward1]
	140039748627136 -> 140039748626992
	140039748627136 [label=AddBackward0]
	140039748627232 -> 140039748627136
	140039748627232 [label=MulBackward0]
	140039748627376 -> 140039748627232
	140039748627376 [label=NativeBatchNormBackward0]
	140039748627520 -> 140039748627376
	140039748627520 [label=ConvolutionBackward0]
	140039748627712 -> 140039748627520
	140039748627712 [label=LeakyReluBackward1]
	140039748627904 -> 140039748627712
	140039748627904 [label=NativeBatchNormBackward0]
	140039748628000 -> 140039748627904
	140039748628000 [label=ConvolutionBackward0]
	140039748627184 -> 140039748628000
	140039748627184 [label=LeakyReluBackward1]
	140039748628336 -> 140039748627184
	140039748628336 [label=ConvolutionBackward0]
	140039748628432 -> 140039748628336
	140039748628432 [label=LeakyReluBackward1]
	140039748640976 -> 140039748628432
	140039748640976 [label=ConvolutionBackward0]
	140039748641072 -> 140039748640976
	140039748869872 [label="encoder1.0.conv.0.weight
 (16, 4, 3, 3)" fillcolor=lightblue]
	140039748869872 -> 140039748641072
	140039748641072 [label=AccumulateGrad]
	140039748641024 -> 140039748640976
	140039748869952 [label="encoder1.0.conv.0.bias
 (16)" fillcolor=lightblue]
	140039748869952 -> 140039748641024
	140039748641024 [label=AccumulateGrad]
	140039748628384 -> 140039748628336
	140039748886592 [label="encoder1.0.conv.2.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140039748886592 -> 140039748628384
	140039748628384 [label=AccumulateGrad]
	140039748628240 -> 140039748628336
	140039748886672 [label="encoder1.0.conv.2.bias
 (32)" fillcolor=lightblue]
	140039748886672 -> 140039748628240
	140039748628240 [label=AccumulateGrad]
	140039748628192 -> 140039748628000
	140039748886832 [label="encoder1.1.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140039748886832 -> 140039748628192
	140039748628192 [label=AccumulateGrad]
	140039748628144 -> 140039748628000
	140039748886912 [label="encoder1.1.conv1.bias
 (32)" fillcolor=lightblue]
	140039748886912 -> 140039748628144
	140039748628144 [label=AccumulateGrad]
	140039748627952 -> 140039748627904
	140039748886992 [label="encoder1.1.bn1.weight
 (32)" fillcolor=lightblue]
	140039748886992 -> 140039748627952
	140039748627952 [label=AccumulateGrad]
	140039748627808 -> 140039748627904
	140039748887072 [label="encoder1.1.bn1.bias
 (32)" fillcolor=lightblue]
	140039748887072 -> 140039748627808
	140039748627808 [label=AccumulateGrad]
	140039748627664 -> 140039748627520
	140039748887632 [label="encoder1.1.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140039748887632 -> 140039748627664
	140039748627664 [label=AccumulateGrad]
	140039748627616 -> 140039748627520
	140039748887712 [label="encoder1.1.conv2.bias
 (32)" fillcolor=lightblue]
	140039748887712 -> 140039748627616
	140039748627616 [label=AccumulateGrad]
	140039748627472 -> 140039748627376
	140039748887792 [label="encoder1.1.bn2.weight
 (32)" fillcolor=lightblue]
	140039748887792 -> 140039748627472
	140039748627472 [label=AccumulateGrad]
	140039748627424 -> 140039748627376
	140039748887872 [label="encoder1.1.bn2.bias
 (32)" fillcolor=lightblue]
	140039748887872 -> 140039748627424
	140039748627424 [label=AccumulateGrad]
	140039748627328 -> 140039748627232
	140039748627328 [label=ExpandBackward0]
	140039748627856 -> 140039748627328
	140039748627856 [label=ViewBackward0]
	140039748628096 -> 140039748627856
	140039748628096 [label=SigmoidBackward0]
	140039748628288 -> 140039748628096
	140039748628288 [label=MmBackward0]
	140039748640880 -> 140039748628288
	140039748640880 [label=LeakyReluBackward1]
	140039748641312 -> 140039748640880
	140039748641312 [label=MmBackward0]
	140039748641408 -> 140039748641312
	140039748641408 [label=ViewBackward0]
	140039748641552 -> 140039748641408
	140039748641552 [label=MeanBackward1]
	140039748627376 -> 140039748641552
	140039748641360 -> 140039748641312
	140039748641360 [label=TBackward0]
	140039748641600 -> 140039748641360
	140039748888192 [label="encoder1.1.se_block.fc.0.weight
 (32, 32)" fillcolor=lightblue]
	140039748888192 -> 140039748641600
	140039748641600 [label=AccumulateGrad]
	140039748640928 -> 140039748628288
	140039748640928 [label=TBackward0]
	140039748641648 -> 140039748640928
	140039748888272 [label="encoder1.1.se_block.fc.2.weight
 (32, 32)" fillcolor=lightblue]
	140039748888272 -> 140039748641648
	140039748641648 [label=AccumulateGrad]
	140039748627184 -> 140039748627136
	140039748626848 -> 140039748625984
	140039748626848 [label=ExpandBackward0]
	140039748627280 -> 140039748626848
	140039748627280 [label=ViewBackward0]
	140039748628048 -> 140039748627280
	140039748628048 [label=SigmoidBackward0]
	140039748627568 -> 140039748628048
	140039748627568 [label=MmBackward0]
	140039748641744 -> 140039748627568
	140039748641744 [label=LeakyReluBackward1]
	140039748641504 -> 140039748641744
	140039748641504 [label=MmBackward0]
	140039748641888 -> 140039748641504
	140039748641888 [label=ViewBackward0]
	140039748642032 -> 140039748641888
	140039748642032 [label=MeanBackward1]
	140039748626992 -> 140039748642032
	140039748641840 -> 140039748641504
	140039748641840 [label=TBackward0]
	140039748642080 -> 140039748641840
	140039748888352 [label="encoder1.2.fc.0.weight
 (32, 32)" fillcolor=lightblue]
	140039748888352 -> 140039748642080
	140039748642080 [label=AccumulateGrad]
	140039748641120 -> 140039748627568
	140039748641120 [label=TBackward0]
	140039748642128 -> 140039748641120
	140039748888432 [label="encoder1.2.fc.2.weight
 (32, 32)" fillcolor=lightblue]
	140039748888432 -> 140039748642128
	140039748642128 [label=AccumulateGrad]
	140039748626704 -> 140039748626656
	140039748888592 [label="bottom.conv.0.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	140039748888592 -> 140039748626704
	140039748626704 [label=AccumulateGrad]
	140039748626560 -> 140039748626656
	140039748888672 [label="bottom.conv.0.bias
 (32)" fillcolor=lightblue]
	140039748888672 -> 140039748626560
	140039748626560 [label=AccumulateGrad]
	140039748626416 -> 140039748626368
	140039748888832 [label="bottom.conv.2.weight
 (64, 32, 3, 3)" fillcolor=lightblue]
	140039748888832 -> 140039748626416
	140039748626416 [label=AccumulateGrad]
	140039748626272 -> 140039748626368
	140039748888912 [label="bottom.conv.2.bias
 (64)" fillcolor=lightblue]
	140039748888912 -> 140039748626272
	140039748626272 [label=AccumulateGrad]
	140039748626128 -> 140039748626032
	140039748889072 [label="up2.up.weight
 (64, 32, 2, 2)" fillcolor=lightblue]
	140039748889072 -> 140039748626128
	140039748626128 [label=AccumulateGrad]
	140039748626080 -> 140039748626032
	140039748889152 [label="up2.up.bias
 (32)" fillcolor=lightblue]
	140039748889152 -> 140039748626080
	140039748626080 [label=AccumulateGrad]
	140039748625984 -> 140039748625840
	140039748625792 -> 140039748625744
	140039748889312 [label="up2.conv_block.conv.0.weight
 (16, 64, 3, 3)" fillcolor=lightblue]
	140039748889312 -> 140039748625792
	140039748625792 [label=AccumulateGrad]
	140039748625648 -> 140039748625744
	140039748889392 [label="up2.conv_block.conv.0.bias
 (16)" fillcolor=lightblue]
	140039748889392 -> 140039748625648
	140039748625648 [label=AccumulateGrad]
	140039748625504 -> 140039748625456
	140039748889552 [label="up2.conv_block.conv.2.weight
 (32, 16, 3, 3)" fillcolor=lightblue]
	140039748889552 -> 140039748625504
	140039748625504 [label=AccumulateGrad]
	140039748625360 -> 140039748625456
	140039748889632 [label="up2.conv_block.conv.2.bias
 (32)" fillcolor=lightblue]
	140039748889632 -> 140039748625360
	140039748625360 [label=AccumulateGrad]
	140039748625216 -> 140039748625120
	140039748889792 [label="final.0.weight
 (1, 32, 1, 1)" fillcolor=lightblue]
	140039748889792 -> 140039748625216
	140039748625216 [label=AccumulateGrad]
	140039748625168 -> 140039748625120
	140039748889872 [label="final.0.bias
 (1)" fillcolor=lightblue]
	140039748889872 -> 140039748625168
	140039748625168 [label=AccumulateGrad]
	140039748625072 -> 140039748625024
	140039748889952 [label="final.1.global_tone_mapping_factor
 (1)" fillcolor=lightblue]
	140039748889952 -> 140039748625072
	140039748625072 [label=AccumulateGrad]
	140039748624832 -> 140039748624496
	140039748624832 [label=LeakyReluBackward1]
	140039748625600 -> 140039748624832
	140039748625600 [label=ConvolutionBackward0]
	140039748625312 -> 140039748625600
	140039748625312 [label=LeakyReluBackward1]
	140039748625936 -> 140039748625312
	140039748625936 [label=ConvolutionBackward0]
	140039748625120 -> 140039748625936
	140039748626320 -> 140039748625936
	140039748890112 [label="final.1.local_tone_conv1.weight
 (1, 1, 3, 3)" fillcolor=lightblue]
	140039748890112 -> 140039748626320
	140039748626320 [label=AccumulateGrad]
	140039748625408 -> 140039748625600
	140039748890272 [label="final.1.local_tone_conv2.weight
 (1, 1, 3, 3)" fillcolor=lightblue]
	140039748890272 -> 140039748625408
	140039748625408 [label=AccumulateGrad]
	140039748624448 -> 140039748610304
}
